{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af69ba04-d958-4c82-bac4-517013ffc042",
   "metadata": {},
   "source": [
    "Importa√ß√µes e configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47a8561-13ce-4ef0-a776-d45a7aef1436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/jovyan/data/raw'), PosixPath('/home/jovyan/data/processed'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Caminhos base dentro do container Jupyter\n",
    "BASE_RAW = Path(\"/home/jovyan/data/raw\")\n",
    "BASE_PROC = Path(\"/home/jovyan/data/processed\")\n",
    "\n",
    "# Garante que a pasta processed existe\n",
    "BASE_PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_RAW, BASE_PROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddba76-96a2-4214-a85e-6ef9751efb49",
   "metadata": {},
   "source": [
    "Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22312fd7-7e92-4909-b70b-abb447136bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_inmet(path: Path) -> pd.DataFrame:\n",
    "\n",
    "    print(f\"\\nüìÑ Lendo arquivo: {path.name}\")\n",
    "    \n",
    "    # 1) Ler CSV bruto\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=';',\n",
    "        skiprows=8,           # pula bloco de metadados\n",
    "        encoding='latin1',\n",
    "        low_memory=False\n",
    "    )\n",
    "    \n",
    "    # 2) Renomear colunas de interesse (s√≥ as que existirem)\n",
    "    mapa_renome = {\n",
    "        'Data': 'data',\n",
    "        'Hora UTC': 'hora',\n",
    "        'TEMPERATURA DO AR - BULBO SECO, HORARIA (¬∞C)': 'temp_ar',\n",
    "        'UMIDADE RELATIVA DO AR, HORARIA (%)': 'umidade',\n",
    "        'RADIACAO GLOBAL (Kj/m¬≤)': 'radiacao',\n",
    "        'RADIACAO GLOBAL (kJ/m¬≤)': 'radiacao',\n",
    "        'RADIACAO GLOBAL': 'radiacao',\n",
    "        'PRECIPITA√á√ÉO TOTAL, HOR√ÅRIO (mm)': 'precipitacao',\n",
    "        'VENTO, VELOCIDADE HORARIA (m/s)': 'vento_vel',\n",
    "        'VENTO, DIRE√á√ÉO HORARIA (gr) (¬∞ (gr))': 'vento_dir',\n",
    "        'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)': 'pressao'\n",
    "    }\n",
    "    df = df.rename(columns={orig: novo for orig, novo in mapa_renome.items() if orig in df.columns})\n",
    "\n",
    "    # 3) Garante que data e hora existem\n",
    "    if 'data' not in df.columns or 'hora' not in df.columns:\n",
    "        raise ValueError(\"Colunas 'Data' e/ou 'Hora UTC' n√£o foram encontradas ap√≥s o rename.\")\n",
    "\n",
    "    # 4) Padronizar 'data' e 'hora' como string\n",
    "    df['data'] = df['data'].astype(str).str.strip()\n",
    "    df['hora'] = df['hora'].astype(str).str.strip()\n",
    "\n",
    "    # 5) Remover ' UTC' da hora, se existir\n",
    "    df['hora'] = df['hora'].str.replace(' UTC', '', regex=False)\n",
    "\n",
    "    # 6) Se hora estiver como 0, 300, 1200 etc, padronizar para HH:MM\n",
    "    mascara_numerica = df['hora'].str.fullmatch(r'\\d{1,4}')\n",
    "    df.loc[mascara_numerica, 'hora'] = (\n",
    "        df.loc[mascara_numerica, 'hora']\n",
    "          .str.zfill(4)\n",
    "          .str[:2] + ':' + df.loc[mascara_numerica, 'hora'].str.zfill(4).str[2:]\n",
    "    )\n",
    "\n",
    "    # 7) Criar coluna datetime (deixa o pandas inferir formato)\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "        df['data'] + ' ' + df['hora'],\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Remover linhas onde datetime n√£o p√¥de ser montado\n",
    "    df = df.dropna(subset=['datetime'])\n",
    "    df = df.set_index('datetime')\n",
    "\n",
    "    # 8) Selecionar colunas de interesse (as que existirem)\n",
    "    colunas_desejadas = ['hora', 'temp_ar', 'umidade', 'radiacao',\n",
    "                         'vento_vel', 'precipitacao', 'pressao']\n",
    "    colunas_presentes = [c for c in colunas_desejadas if c in df.columns]\n",
    "    df = df[colunas_presentes]\n",
    "\n",
    "    # 9) Converter vari√°veis num√©ricas para float\n",
    "    variaveis_numericas = [c for c in colunas_presentes if c != 'hora']\n",
    "\n",
    "    for col in variaveis_numericas:\n",
    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False).str.strip()\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # 10) Remover colunas que est√£o 100% NaN (por exemplo, radiacao ausente o ano todo)\n",
    "    colunas_todas_nan = [c for c in variaveis_numericas if df[c].isna().sum() == len(df)]\n",
    "    if colunas_todas_nan:\n",
    "        print(\"   ‚ö† Removendo colunas 100% NaN:\", colunas_todas_nan)\n",
    "        df = df.drop(columns=colunas_todas_nan)\n",
    "        variaveis_numericas = [c for c in variaveis_numericas if c not in colunas_todas_nan]\n",
    "\n",
    "    # 11) Interpolar valores faltantes ao longo do tempo\n",
    "    if variaveis_numericas:\n",
    "        df[variaveis_numericas] = df[variaveis_numericas].interpolate(\n",
    "            method='time'\n",
    "        )\n",
    "\n",
    "        # Opcional: preencher pontas (in√≠cio/fim) com ffill/bfill\n",
    "        df[variaveis_numericas] = df[variaveis_numericas].ffill().bfill()\n",
    "\n",
    "    # 12) Remover apenas linhas em que TODAS as vari√°veis num√©ricas s√£o NaN (caso sobrem)\n",
    "    if variaveis_numericas:\n",
    "        mask_all_nan = df[variaveis_numericas].isna().all(axis=1)\n",
    "        n_all_nan = mask_all_nan.sum()\n",
    "        if n_all_nan > 0:\n",
    "            print(f\"   ‚ö† Removendo {n_all_nan} linhas 100% NaN nas vari√°veis num√©ricas.\")\n",
    "            df = df[~mask_all_nan]\n",
    "\n",
    "    # 13) Criar features auxiliares\n",
    "    df['hora_num'] = df.index.hour\n",
    "    df['mes'] = df.index.month\n",
    "\n",
    "    print(f\"   ‚úÖ Registros ap√≥s tratamento: {len(df)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347a54b-dd10-4f8e-9542-a5f6b54c1f2a",
   "metadata": {},
   "source": [
    "Loop para processar Petrolina e Garanhuns (2020 a 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dffff4fb-f874-4f54-ad59-98c61df4e7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2020_A_31-12-2020.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2020_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2020_A_31-12-2020.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2020_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2021_A_31-12-2021.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2021_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2021_A_31-12-2021.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2021_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2022_A_31-12-2022.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2022_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2022_A_31-12-2022.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2022_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2023_A_31-12-2023.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['radiacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2023_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2023_A_31-12-2023.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2023_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2024_A_31-12-2024.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['radiacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2024_tratado.csv\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2024_A_31-12-2024.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['precipitacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2024_tratado.csv\n"
     ]
    }
   ],
   "source": [
    "anos = ['2020', '2021', '2022', '2023', '2024']\n",
    "cidades = ['PETROLINA', 'GARANHUNS']\n",
    "\n",
    "for ano in anos:\n",
    "    pasta_ano = BASE_RAW / ano\n",
    "    \n",
    "    for cidade in cidades:\n",
    "        # procura arquivos do tipo *CIDADE*.CSV dentro do ano\n",
    "        arquivos = list(pasta_ano.glob(f\"*{cidade}*.CSV\"))\n",
    "        \n",
    "        if not arquivos:\n",
    "            print(f\"\\nüö´ Nenhum arquivo encontrado para {cidade} em {ano}\")\n",
    "            continue\n",
    "        \n",
    "        for arq in arquivos:\n",
    "            df_tratado = processar_inmet(arq)\n",
    "            \n",
    "            # nome do arquivo de sa√≠da\n",
    "            nome_saida = f\"{cidade.lower()}_{ano}_tratado.csv\"\n",
    "            caminho_saida = BASE_PROC / nome_saida\n",
    "            \n",
    "            df_tratado.to_csv(caminho_saida)\n",
    "            print(f\"   üíæ Salvo em: {caminho_saida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4007a76",
   "metadata": {},
   "source": [
    "Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e97da1-d3a9-4202-8c31-0032e0b49ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram encontrados 10 arquivos tratados.\n",
      "\n",
      "üìÑ Arquivo: petrolina_2020_tratado.csv\n",
      "   ‚û§ Linhas: 8784\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: petrolina_2022_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: garanhuns_2024_tratado.csv\n",
      "   ‚û§ Linhas: 8784\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora         0\n",
      "temp_ar      0\n",
      "umidade      0\n",
      "radiacao     0\n",
      "vento_vel    0\n",
      "pressao      0\n",
      "hora_num     0\n",
      "mes          0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: garanhuns_2023_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: petrolina_2024_tratado.csv\n",
      "   ‚û§ Linhas: 8784\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: petrolina_2023_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: garanhuns_2022_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: garanhuns_2021_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: petrolina_2021_tratado.csv\n",
      "   ‚û§ Linhas: 8760\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n",
      "üìÑ Arquivo: garanhuns_2020_tratado.csv\n",
      "   ‚û§ Linhas: 8784\n",
      "   ‚û§ NaNs por coluna:\n",
      "hora            0\n",
      "temp_ar         0\n",
      "umidade         0\n",
      "radiacao        0\n",
      "vento_vel       0\n",
      "precipitacao    0\n",
      "pressao         0\n",
      "hora_num        0\n",
      "mes             0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "processed_path = BASE_PROC\n",
    "\n",
    "arquivos_tratados = list(processed_path.glob(\"*_tratado.csv\"))\n",
    "\n",
    "print(\"Foram encontrados\", len(arquivos_tratados), \"arquivos tratados.\\n\")\n",
    "\n",
    "for arquivo in arquivos_tratados:\n",
    "    df = pd.read_csv(arquivo, index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(\"üìÑ Arquivo:\", arquivo.name)\n",
    "    print(\"   ‚û§ Linhas:\", len(df))\n",
    "    print(\"   ‚û§ NaNs por coluna:\")\n",
    "    print(df.isna().sum().to_string())\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21afadf-9014-456a-a43a-20bce3879a33",
   "metadata": {},
   "source": [
    "Nota:\n",
    "\n",
    "Para lidar com valores clim√°ticos faltantes nos arquivos do INMET, utilizamos a t√©cnica de interpola√ß√£o temporal, que √© um m√©todo recomendado internacionalmente para reconstru√ß√£o de s√©ries meteorol√≥gicas. Em termos simples, a interpola√ß√£o preenche lacunas usando os valores anteriores e posteriores como refer√™ncia. Por exemplo: se √†s 10h a temperatura √© 22¬∞C e √†s 12h √© 24¬∞C, a interpola√ß√£o estima que √†s 11h ela seria aproximadamente 23¬∞C. Isso evita descartar horas inteiras ‚Äî o que reduziria drasticamente a qualidade do conjunto de dados ‚Äî e mant√©m a continuidade natural do clima, que muda de forma gradual ao longo do tempo. Esse procedimento foi aplicado usando df.interpolate(method='time'), que utiliza o √≠ndice de datas do pr√≥prio dataframe para estimar valores de forma coerente com a evolu√ß√£o temporal. O uso de interpola√ß√£o em dados clim√°ticos √© amplamente adotado por institui√ß√µes como o NOAA ‚Äì National Oceanic and Atmospheric Administration, que afirma que a interpola√ß√£o linear √© adequada para preenchimento de falhas curtas em s√©ries meteorol√≥gicas cont√≠nuas (NOAA, Climate Data Interpolation Guidelines, 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40053316",
   "metadata": {},
   "source": [
    "Configura√ß√£o SnowFlake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa7bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√µes do Snowflake definidas.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "SNOWFLAKE_USER = \"APP_USER_METEO\"\n",
    "SNOWFLAKE_PASSWORD = \"B@tataQuente!2025\" \n",
    "SNOWFLAKE_ACCOUNT = \"gcifwsf-dz69699\" \n",
    "SNOWFLAKE_WAREHOUSE = \"WH_METEORO_BI\"\n",
    "SNOWFLAKE_DATABASE = \"DB_INMET_PE\"\n",
    "SNOWFLAKE_SCHEMA = \"DATA_ESTRUTURADA\"\n",
    "SNOWFLAKE_TABLE = \"DADOS_INMET_HORARIO\"\n",
    "\n",
    "# Cria a string de conex√£o para uso em fun√ß√µes\n",
    "SNOWFLAKE_CONN_PARAMS = {\n",
    "    \"user\": SNOWFLAKE_USER,\n",
    "    \"password\": SNOWFLAKE_PASSWORD,\n",
    "    \"account\": SNOWFLAKE_ACCOUNT,\n",
    "    \"warehouse\": SNOWFLAKE_WAREHOUSE,\n",
    "    \"database\": SNOWFLAKE_DATABASE,\n",
    "    \"schema\": SNOWFLAKE_SCHEMA\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√µes do Snowflake definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de389ebe",
   "metadata": {},
   "source": [
    "Fun√ß√£o para carregar dados no SnowFlake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f4c8a-ca59-4034-b9fd-054a300b87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUN√á√ÉO PARA CARREGAR DADOS NO SNOWFLAKE\n",
    "# ==============================================================================\n",
    "\n",
    "def carregar_para_snowflake(df: pd.DataFrame, nome_tabela: str):\n",
    "    \"\"\"\n",
    "    Conecta ao Snowflake e carrega um DataFrame Pandas para a tabela especificada.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela {nome_tabela}...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Conex√£o\n",
    "        conn = snowflake.connector.connect(**SNOWFLAKE_CONN_PARAMS)\n",
    "        \n",
    "        # 2. Executa a carga usando write_pandas\n",
    "        success, n_chunks, n_rows, output = write_pandas(\n",
    "            conn, \n",
    "            df, \n",
    "            table_name=nome_tabela,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "            auto_create_table=False \n",
    "        )\n",
    "        \n",
    "        # 3. Confirma√ß√£o\n",
    "        print(f\"   ‚úÖ Carga conclu√≠da. Linhas carregadas: {n_rows}\")\n",
    "        print(f\"   ‚úÖ Arquivos enviados: {n_chunks} chunk(s).\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO ao carregar para o Snowflake: {e}\")\n",
    "        print(\"   Primeiras linhas do DataFrame com erro:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    finally:\n",
    "        if 'conn' in locals() and conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3d845",
   "metadata": {},
   "source": [
    "Loop para processar, salvar CSV localmente e carregar no SnowFlake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Tabela DADOS_INMET_HORARIO truncada com sucesso no Snowflake.\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2020_A_31-12-2020.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2020_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8784\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2020_A_31-12-2020.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2020_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8784\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2021_A_31-12-2021.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2021_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2021_A_31-12-2021.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2021_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2022_A_31-12-2022.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2022_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2022_A_31-12-2022.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2022_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2023_A_31-12-2023.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['radiacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2023_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2023_A_31-12-2023.CSV\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8760\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2023_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8760\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A307_PETROLINA_01-01-2024_A_31-12-2024.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['radiacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/petrolina_2024_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8784\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n",
      "\n",
      "üìÑ Lendo arquivo: INMET_NE_PE_A322_GARANHUNS_01-01-2024_A_31-12-2024.CSV\n",
      "   ‚ö† Removendo colunas 100% NaN: ['precipitacao']\n",
      "   ‚úÖ Registros ap√≥s tratamento: 8784\n",
      "   üíæ Salvo em: /home/jovyan/data/processed/garanhuns_2024_tratado.csv\n",
      "\n",
      "‚ùÑÔ∏è Conectando ao Snowflake para carregar a tabela DADOS_INMET_HORARIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py:407: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  [pandas.api.types.is_datetime64tz_dtype(df[c]) for c in df.columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carga conclu√≠da. Linhas carregadas: 8784\n",
      "   ‚úÖ Arquivos enviados: 1 chunk(s).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# LOOP PARA PROCESSAR, SALVAR CSV LOCALMENTE E CARREGAR NO SNOWFLAKE\n",
    "# ==============================================================================\n",
    "\n",
    "try:\n",
    "    with snowflake.connector.connect(**SNOWFLAKE_CONN_PARAMS) as conn:\n",
    "        conn.cursor().execute(f\"TRUNCATE TABLE {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.{SNOWFLAKE_TABLE}\")\n",
    "        print(f\"\\n‚ö†Ô∏è Tabela {SNOWFLAKE_TABLE} truncada com sucesso no Snowflake.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO ao tentar truncar a tabela no Snowflake: {e}\")\n",
    "\n",
    "for ano in anos:\n",
    "    pasta_ano = BASE_RAW / ano\n",
    "    \n",
    "    for cidade in cidades:\n",
    "        estacao_id = cidade.lower()\n",
    "        \n",
    "        arquivos = list(pasta_ano.glob(f\"*{cidade}*.CSV\"))\n",
    "        \n",
    "        if not arquivos:\n",
    "            print(f\"\\nüö´ Nenhum arquivo encontrado para {cidade} em {ano}\")\n",
    "            continue\n",
    "        \n",
    "        for arq in arquivos:\n",
    "            # 1. Processamento e Limpeza (Fun√ß√£o existente)\n",
    "            df_tratado = processar_inmet(arq)\n",
    "            \n",
    "            # 2. Ajustes Finais para o Snowflake\n",
    "            \n",
    "            # 2a. Adiciona a coluna ESTACAO_ID\n",
    "            df_tratado['ESTACAO_ID'] = estacao_id\n",
    "            \n",
    "            # 2b. Renomeia colunas para bater com o DDL final\n",
    "            # Colunas no DDL: TEMP_AR, UMIDADE, PRESSAO, VENTO_VEL, RADIACAO, PRECIPITACAO\n",
    "            mapa_cols_snowflake = {\n",
    "                'pressao': 'PRESSAO',\n",
    "                'radiacao': 'RADIACAO',\n",
    "                'vento_vel': 'VENTO_VEL',\n",
    "                'precipitacao': 'PRECIPITACAO',\n",
    "                'temp_ar': 'TEMP_AR',\n",
    "                'umidade': 'UMIDADE',\n",
    "                'hora_num': 'HORA_NUM',\n",
    "                'mes': 'MES',\n",
    "                'hora': 'HORA'\n",
    "            }\n",
    "\n",
    "            df_final = df_tratado.reset_index().rename(columns=mapa_cols_snowflake)\n",
    "        \n",
    "            if 'index' in df_final.columns:\n",
    "                df_final = df_final.drop(columns=['index'])\n",
    "\n",
    "            df_final.rename(columns={'datetime': 'DATETIME'}, inplace=True)\n",
    "            \n",
    "            # Reorganiza as colunas na ordem do DDL do Snowflake\n",
    "            colunas_ddl = [\n",
    "                'DATETIME', 'ESTACAO_ID', 'TEMP_AR', 'UMIDADE', 'PRESSAO', \n",
    "                'VENTO_VEL', 'RADIACAO', 'PRECIPITACAO', 'HORA_NUM', 'MES', 'HORA'\n",
    "            ]\n",
    "            \n",
    "            # Filtra colunas que realmente existem no DataFrame (ex: 'RADIACAO' pode ter sido removida)\n",
    "            colunas_existentes = [c for c in colunas_ddl if c in df_final.columns]\n",
    "            df_final = df_final[colunas_existentes]\n",
    "\n",
    "\n",
    "            # 3. Salva CSV Localmente \n",
    "            nome_saida = f\"{estacao_id}_{ano}_tratado.csv\"\n",
    "            caminho_saida = BASE_PROC / nome_saida\n",
    "            df_tratado.to_csv(caminho_saida)\n",
    "            print(f\"   üíæ Salvo em: {caminho_saida}\")\n",
    "            \n",
    "            # 4. Carga para o Snowflake\n",
    "            carregar_para_snowflake(df_final, SNOWFLAKE_TABLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
