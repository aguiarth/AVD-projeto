# ğŸŒ¦ï¸ AVD - Pipeline de BI ClimÃ¡tico

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11-blue.svg)
![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![License](https://img.shields.io/badge/License-Academic-lightgrey.svg)

**Pipeline completo de Business Intelligence para anÃ¡lise e visualizaÃ§Ã£o de dados meteorolÃ³gicos do INMET**

[ğŸ“‹ Ãndice](#-Ã­ndice) â€¢ [ğŸš€ InÃ­cio RÃ¡pido](#-inÃ­cio-rÃ¡pido) â€¢ [ğŸ“š DocumentaÃ§Ã£o](#-documentaÃ§Ã£o) â€¢ [ğŸ¤ Equipe](#-equipe)

</div>

---

## ğŸ“‹ Ãndice

1. [IntroduÃ§Ã£o e Objetivo](#1-introduÃ§Ã£o-e-objetivo)
2. [Membros do Projeto](#2-membros-do-projeto)
3. [Arquitetura do Pipeline](#3-arquitetura-do-pipeline)
4. [Estrutura do RepositÃ³rio](#4-estrutura-do-repositÃ³rio)
5. [Tecnologias Utilizadas](#5-tecnologias-utilizadas)
6. [Requisitos e DependÃªncias](#6-requisitos-e-dependÃªncias)
7. [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#7-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
8. [InstruÃ§Ãµes de ExecuÃ§Ã£o](#8-instruÃ§Ãµes-de-execuÃ§Ã£o)
9. [Notebooks do Projeto](#9-notebooks-do-projeto)
10. [Scripts Auxiliares](#10-scripts-auxiliares)
11. [Troubleshooting](#11-troubleshooting)
12. [Resultados e ConclusÃµes](#12-resultados-e-conclusÃµes)

---

## 1. IntroduÃ§Ã£o e Objetivo

Este projeto implementa um **pipeline completo de Business Intelligence (BI)** para anÃ¡lise e visualizaÃ§Ã£o de dados meteorolÃ³gicos do **INMET (Instituto Nacional de Meteorologia)**, focando no estado de **Pernambuco**, com Ãªnfase nas estaÃ§Ãµes de **Petrolina** e **Garanhuns**.

### ğŸ¯ Objetivo Central

Aplicar tÃ©cnicas de **Agrupamento (Clustering) K-Means** para identificar **PadrÃµes ClimÃ¡ticos Chave** utilizando dados agregados de temperatura, umidade, radiaÃ§Ã£o solar, precipitaÃ§Ã£o e pressÃ£o atmosfÃ©rica. O resultado deste agrupamento Ã© visualizado em dashboards interativos no **ThingsBoard**.

### ğŸ“Š Dados Processados

- **PerÃ­odo:** 2020 a 2024
- **EstaÃ§Ãµes:** Petrolina (A307) e Garanhuns (A322)
- **FrequÃªncia:** Dados horÃ¡rios
- **VariÃ¡veis:** Temperatura, Umidade, RadiaÃ§Ã£o, Vento, PrecipitaÃ§Ã£o, PressÃ£o

## 2. Membros do Projeto

| Nome | UsuÃ¡rio |
| :--- | :--- |
| Lisa Matubara | `lilymtbr` |
| Luziane Santos | `luzianes` |
| Maria JÃºlia Peixoto | `majupeixoto` |
| Matheus Velame | `MatheusVelame` |
| Paulo Rago | `paulo_rago` |
| ThaÃ­s Aguiar | `aguiarth` |

* **Disciplina:** AnÃ¡lise e VisualizaÃ§Ã£o de Dados - 2025.2  
* **InstituiÃ§Ã£o:** CESAR School

## 3. Arquitetura do Pipeline

A soluÃ§Ã£o Ã© baseada em contÃªineres **Docker** e orquestrada via **Docker Compose**, abrangendo as seguintes camadas:

| ServiÃ§o | FunÃ§Ã£o Principal | Porta | URL de Acesso |
| :--- | :--- | :--- | :--- |
| **JupyterLab** | Ambiente de anÃ¡lise, tratamento de dados e modelagem | `8888` | `http://localhost:8888` |
| **FastAPI** | Interface de ingestÃ£o dos dados brutos do INMET e integraÃ§Ã£o com MinIO/S3 | `8000` | `http://localhost:8000` |
| **MinIO/S3** | Data Lake - Armazenamento de dados brutos e modelos | `9000` (API)<br>`9001` (Console) | `http://localhost:9001` |
| **PostgreSQL** | Data Warehouse - Banco de dados relacional para armazenamento estruturado | `5432` | `http://localhost:8085` (Adminer) |
| **Adminer** | Interface web para gerenciamento do PostgreSQL | `8085` | `http://localhost:8085` |
| **MLFlow** | Registro e versionamento do modelo de K-Means e artefatos | `5000` | `http://localhost:5000` |
| **ThingsBoard** | Plataforma IoT para visualizaÃ§Ã£o de dados e dashboards | `8090` | `http://localhost:8090` |

### ğŸ”„ Fluxo Detalhado do Pipeline

```mermaid
graph TD
    A[Dados Limpos] --> B[send_inmet_to_tb.py]
    B --> C[ThingsBoard]
    C -->|Regra de NegÃ³cio| D[MinIO/S3]
    D -->|ETL| E[PostgreSQL]
    E -->|ExtraÃ§Ã£o| F[Jupyter Notebook]
    F -->|K-Means| G[MLFlow]
    F --> H[Modelos e Resultados]
    H --> C
```

#### Fluxo de Dados Detalhado

1. **IngestÃ£o:** Os dados limpos sÃ£o enviados ao ThingsBoard via script Python (`scripts/send_inmet_to_tb.py`).

2. **ThingsBoard â†’ MinIO:** O ThingsBoard aplica uma **Regra de NegÃ³cio** para persistir os dados brutos no MinIO/S3 (Data Lake).

3. **MinIO â†’ PostgreSQL:** A transferÃªncia do data lake (MinIO) para o data warehouse (PostgreSQL) Ã© realizada atravÃ©s de um script de ETL dedicado (`scripts/etl_minio_to_postgres.py`).

4. **Modelagem:** O Jupyter Notebook extrai os dados estruturados diretamente do PostgreSQL para o Machine Learning (K-Means), que Ã© rastreado pelo MLFlow.

5. **VisualizaÃ§Ã£o:** O ThingsBoard consome os resultados do agrupamento para gerar dashboards interativos.


## 4. Estrutura do RepositÃ³rio

```
AVD-projeto-1/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados brutos do INMET (CSV)
â”‚   â”‚   â”œâ”€â”€ 2020/
â”‚   â”‚   â”‚   â”œâ”€â”€ INMET_NE_PE_A307_PETROLINA_01-01-2020_A_31-12-2020.CSV
â”‚   â”‚   â”‚   â””â”€â”€ INMET_NE_PE_A322_GARANHUNS_01-01-2020_A_31-12-2020.CSV
â”‚   â”‚   â”œâ”€â”€ 2021/
â”‚   â”‚   â”‚   â”œâ”€â”€ INMET_NE_PE_A307_PETROLINA_01-01-2021_A_31-12-2021.CSV
â”‚   â”‚   â”‚   â””â”€â”€ INMET_NE_PE_A322_GARANHUNS_01-01-2021_A_31-12-2021.CSV
â”‚   â”‚   â”œâ”€â”€ 2022/
â”‚   â”‚   â”‚   â”œâ”€â”€ INMET_NE_PE_A307_PETROLINA_01-01-2022_A_31-12-2022.CSV
â”‚   â”‚   â”‚   â””â”€â”€ INMET_NE_PE_A322_GARANHUNS_01-01-2022_A_31-12-2022.CSV
â”‚   â”‚   â”œâ”€â”€ 2023/
â”‚   â”‚   â”‚   â”œâ”€â”€ INMET_NE_PE_A307_PETROLINA_01-01-2023_A_31-12-2023.CSV
â”‚   â”‚   â”‚   â””â”€â”€ INMET_NE_PE_A322_GARANHUNS_01-01-2023_A_31-12-2023.CSV
â”‚   â”‚   â””â”€â”€ 2024/
â”‚   â”‚       â”œâ”€â”€ INMET_NE_PE_A307_PETROLINA_01-01-2024_A_31-12-2024.CSV
â”‚   â”‚       â””â”€â”€ INMET_NE_PE_A322_GARANHUNS_01-01-2024_A_31-12-2024.CSV
â”‚   â””â”€â”€ processed/               # Dados tratados (CSV)
â”‚       â”œâ”€â”€ petrolina_*_tratado.csv
â”‚       â””â”€â”€ garanhuns_*_tratado.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_carregar_dados.ipynb          # Notebook exploratÃ³rio
â”‚   â”œâ”€â”€ 01_tratamento_dados_inmet.ipynb  # Processamento completo
â”‚   â”œâ”€â”€ 02_Modelagem.ipynb               # Modelagem e clustering
â”‚   â”œâ”€â”€ 03_testando_modelo.ipynb         # Teste previsÃ£o
â”‚   â”œâ”€â”€ classification_report.json
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â”œâ”€â”€ decision_tree_classifier.pkl
â”‚   â””â”€â”€ random_forest_regressor.pkl
â”œâ”€â”€ fastapi/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # API de ingestÃ£o
â”‚   â”œâ”€â”€ requirements.txt          # DependÃªncias FastAPI
â”‚   â””â”€â”€ Dockerfile                # Imagem Docker FastAPI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ etl_minio_to_postgres.py  # ETL MinIO â†’ PostgreSQL
â”‚   â”œâ”€â”€ send_inmet_to_tb.py       # Envio de dados para ThingsBoard
â”‚   â””â”€â”€ test_pipeline.py          # Testes do pipeline
â”œâ”€â”€ thingsboard/
â”‚   â””â”€â”€ projetoavd.json
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml            # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ Dockerfile.jupyter            # Dockerfile do Jupyter
â””â”€â”€ README.md                     # Este arquivo
```

## 5. Tecnologias Utilizadas

### ğŸ³ Infraestrutura e ContainerizaÃ§Ã£o
- **Docker** (20.10+) - ContainerizaÃ§Ã£o de aplicaÃ§Ãµes
- **Docker Compose** (2.0+) - OrquestraÃ§Ã£o de serviÃ§os

### ğŸ”§ Backend e APIs
- **FastAPI** (0.100+) - Framework web moderno para APIs REST
- **Uvicorn** - Servidor ASGI de alta performance
- **Python 3.11** - Linguagem de programaÃ§Ã£o principal

### ğŸ’¾ Armazenamento de Dados
- **MinIO** - Data Lake - Armazenamento de objetos compatÃ­vel com S3
- **PostgreSQL 15** - Data Warehouse - Banco de dados relacional
- **SQLAlchemy** - ORM para Python

### ğŸ“Š AnÃ¡lise de Dados e Machine Learning
- **Pandas** - ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Scikit-learn** - Machine Learning (K-Means, StandardScaler)
- **JupyterLab** - Ambiente de desenvolvimento interativo

### ğŸ“ˆ VisualizaÃ§Ã£o
- **Matplotlib** - VisualizaÃ§Ãµes estÃ¡ticas
- **Seaborn** - VisualizaÃ§Ãµes estatÃ­sticas avanÃ§adas

### ğŸ”„ MLOps e Versionamento
- **MLFlow** (v2.7.1) - Gerenciamento do ciclo de vida de modelos
- **Git** - Controle de versÃ£o

### ğŸŒ IoT e VisualizaÃ§Ã£o
- **ThingsBoard** - Plataforma IoT para visualizaÃ§Ã£o e dashboards
- **Adminer** - Interface web para PostgreSQL

### ğŸ“¡ IntegraÃ§Ã£o e ComunicaÃ§Ã£o
- **Requests** - Cliente HTTP para Python
- **psycopg2-binary** - Adaptador PostgreSQL para Python
- **python-multipart** - Suporte para upload de arquivos

## 6. Requisitos e DependÃªncias

### ğŸ“¦ DependÃªncias do FastAPI

Arquivo: `fastapi/requirements.txt`

```
fastapi
uvicorn[standard]
pandas
python-multipart
minio
requests
psycopg2-binary
sqlalchemy
```

### ğŸ“¦ DependÃªncias do JupyterLab

Instaladas via `Dockerfile.jupyter`:

```
minio
psycopg2-binary
sqlalchemy
```

### ğŸ“¦ DependÃªncias dos Notebooks

Bibliotecas Python utilizadas nos notebooks:

```python
# AnÃ¡lise de Dados
pandas
numpy

# Machine Learning
scikit-learn

# VisualizaÃ§Ã£o
matplotlib
seaborn

# IntegraÃ§Ã£o
minio
psycopg2-binary
sqlalchemy
requests
```

### ğŸ“¦ DependÃªncias dos Scripts

```python
# ETL e Processamento
pandas
minio
sqlalchemy
psycopg2-binary
```

# ComunicaÃ§Ã£o
requests

## 7. InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 7.1. PrÃ©-requisitos

```bash
# Verificar versÃ£o do Docker
docker --version

# Verificar versÃ£o do Docker Compose
docker-compose --version

# Instalar Docker (se necessÃ¡rio)
# Ubuntu/Debian:
sudo apt-get update
sudo apt-get install docker.io docker-compose

# macOS (via Homebrew):
brew install docker docker-compose

# Windows 
# Instalar Docker Desktop (inclui Docker Compose)
# Baixar de: https://www.docker.com/products/docker-desktop
```

### 7.2. Requisitos do Sistema

- **Docker** (versÃ£o 20.10 ou superior)
- **Docker Compose** (versÃ£o 2.0 ou superior)
- **Git** (para clonar o repositÃ³rio)
- **8GB de RAM** (recomendado)
- **10GB de espaÃ§o em disco** (para dados e imagens)
- **ConexÃ£o estÃ¡vel com a internet** (para download de imagens Docker)

### 7.3. Clonagem do RepositÃ³rio

Comandos para Linux / macOS / Windows:

```bash
git clone https://github.com/aguiarth/AVD-projeto.git
cd AVD-projeto
```

## 8. InstruÃ§Ãµes de ExecuÃ§Ã£o

### 8.1. Subir a Infraestrutura

Comandos para Linux / macOS / Windows (PowerShell / CMD):

```bash
# Construir as imagens e iniciar os serviÃ§os
docker-compose up -d --build

# Verificar se todos os serviÃ§os estÃ£o rodando
docker-compose ps
```

### 8.2. Verificar Status dos ServiÃ§os

VocÃª deve ver todos os serviÃ§os com status `Up`:

- `jupyter-uva` (JupyterLab)
- `thingsboard` (ThingsBoard)
- `fastapi-clima` (FastAPI)
- `minio` (MinIO)
- `mlflow_server` (MLFlow)
- `postgres-avd` (PostgreSQL)
- `adminer-avd` (Adminer)

### 8.3. Acessar os ServiÃ§os

| ServiÃ§o | URL | Credenciais |
| :--- | :--- | :--- |
| **JupyterLab** | `http://localhost:8888` | Sem token |
| **FastAPI** | `http://localhost:8000` | - |
| **FastAPI Docs** | `http://localhost:8000/docs` | - |
| **MinIO Console** | `http://localhost:9001` | `admin` / `admin12345` |
| **MLFlow** | `http://localhost:5000` | - |
| **ThingsBoard** | `http://localhost:8090` | `tenant@thingsboard.org` / `tenant` |
| **Adminer** | `http://localhost:8085` | Sistema: `PostgreSQL`<br>Servidor: `postgres`<br>UsuÃ¡rio: `postgres`<br>Senha: `postgres`<br>Base de dados: `clima` |

### 8.4. ExecuÃ§Ã£o do Pipeline

#### Passo 1: Processamento dos Dados

1. **Acesse o JupyterLab:** `http://localhost:8888`

2. **Execute o notebook `01_tratamento_dados_inmet.ipynb`:**
   - Este notebook processa todos os arquivos CSV do INMET (2020-2024)
   - Aplica limpeza, interpolaÃ§Ã£o temporal e tratamento de valores faltantes
   - Salva os dados tratados em `/data/processed/`

   **VariÃ¡veis processadas:**
   - Temperatura do ar (Â°C)
   - Umidade relativa (%)
   - RadiaÃ§Ã£o global (kJ/mÂ²) - quando disponÃ­vel
   - Velocidade do vento (m/s)
   - PrecipitaÃ§Ã£o (mm)
   - PressÃ£o atmosfÃ©rica (mB)

3. **Para exploraÃ§Ã£o rÃ¡pida, use o notebook `01_carregar_dados.ipynb`:**
   - Permite visualizar e explorar um arquivo especÃ­fico
   - Usa a mesma funÃ§Ã£o de processamento do notebook principal

#### Passo 2: Thingsboard->MinIO->PostgreSQL->Jupyter->MLFlow/MinIO->Thingsboard

1. **Acesse o ThingsBoard:** `http://localhost:8090`
   - Credenciais padrÃ£o: `tenant@thingsboard.org` / `tenant`

2. **Configure dispositivos e dashboards:**
   - Crie dispositivos para cada estaÃ§Ã£o (Petrolina, Garanhuns)
   - Configure uma **Regra de NegÃ³cio** no ThingsBoard para persistir dados no MinIO
   - Use o script `scripts/send_inmet_to_tb.py` para enviar dados limpos ao ThingsBoard
   - Execute o script `scripts/etl_minio_to_postgres.py` para transferir dados do MinIO para PostgreSQL
   - Crie dashboards para visualizar os clusters identificados
3. Modelagem e MLOps (K-Means) ğŸ¤–
    - Esta etapa usa os dados estruturados no PostgreSQL para aplicar a Machine Learning e registrar os artefatos.
    - Execute o notebook 02_modelagem.ipynb:
    - Este notebook carrega os dados processados do PostgreSQL (tabela inmet_raw).
    - Aplica o Agrupamento K-Means (clusterizaÃ§Ã£o) nos dados de Petrolina para identificar padrÃµes climÃ¡ticos semanais.
    - Treina modelos de RegressÃ£o e ClassificaÃ§Ã£o para Garanhuns, utilizando os clusters gerados como features.
    - Verifique o MLFlow: ApÃ³s a execuÃ§Ã£o, acesse http://localhost:5000 para visualizar as mÃ©tricas (MAE, RÂ², AcurÃ¡cia) e parÃ¢metros registrados.
    - Verifique o MinIO (Data Lake):
    - Os modelos serializados (.pkl) e relatÃ³rios de classificaÃ§Ã£o sÃ£o salvos no MinIO (http://localhost:9001), no bucket inmet-models.
#### Passo 3: VisualizaÃ§Ã£o no ThingsBoard
    - Acesse o ThingsBoard: http://localhost:8090

## 9. Notebooks do Projeto

### ğŸ““ `01_carregar_dados.ipynb`

**PropÃ³sito:** Notebook exploratÃ³rio para visualizaÃ§Ã£o e anÃ¡lise rÃ¡pida de dados.

**Funcionalidades:**
- Lista arquivos CSV disponÃ­veis
- Processa um arquivo especÃ­fico usando a funÃ§Ã£o `processar_inmet()`
- Exibe estatÃ­sticas descritivas
- Verifica valores faltantes
- Visualiza amostras dos dados

**Quando usar:** Para exploraÃ§Ã£o inicial dos dados ou anÃ¡lise de um arquivo especÃ­fico.

### ğŸ““ `01_tratamento_dados_inmet.ipynb`

**PropÃ³sito:** Processamento completo de todos os arquivos do INMET.

**Funcionalidades:**
- Processa todos os arquivos CSV (2020-2024, Petrolina e Garanhuns)
- Aplica funÃ§Ã£o `processar_inmet()` padronizada
- Interpola valores faltantes usando mÃ©todo temporal
- Remove colunas 100% vazias (ex: radiaÃ§Ã£o quando ausente)
- Cria features auxiliares (hora_num, mes)
- Salva dados tratados em CSV em `/data/processed/`

**Tratamento aplicado:**
- ConversÃ£o de vÃ­rgula para ponto decimal
- PadronizaÃ§Ã£o de formato de hora
- CriaÃ§Ã£o de Ã­ndice datetime
- InterpolaÃ§Ã£o temporal de valores faltantes
- Preenchimento de bordas (ffill/bfill)

**Quando usar:** Para processar todos os dados e preparar para modelagem.

### ğŸ““ `02_modelagem.ipynb` (Modelagem, AvaliaÃ§Ã£o e MLOps)

O notebook detalha o pipeline de anÃ¡lise e criaÃ§Ã£o de **dois modelos supervisionados** (RegressÃ£o e ClassificaÃ§Ã£o) para a cidade de Garanhuns, utilizando os padrÃµes climÃ¡ticos extraÃ­dos de Petrolina.

**PropÃ³sito:**  PropÃ³sito e Abordagem

O principal objetivo Ã© utilizar um modelo de **ClusterizaÃ§Ã£o** (K-Means) treinado com dados de **Petrolina** para gerar *labels* (padrÃµes climÃ¡ticos/clusters) que sÃ£o, entÃ£o, usados para construir modelos de previsÃ£o para **Garanhuns**.

**Funcionalidades e Fluxo de ExecuÃ§Ã£o:**

| Etapa | Detalhe |
| :--- | :--- |
| **ExtraÃ§Ã£o de Dados** | Extrai dados brutos (`inmet_raw`) diretamente do **PostgreSQL**. |
| **Tratamento de Outliers** | Aplica a remoÃ§Ã£o de outliers por cidade via Intervalo Interquartil (IQR). |
| **AgregaÃ§Ã£o Semanal** | Transforma dados horÃ¡rios em dados semanais (ISO year-week) para ambas as cidades. |
| **K-Means (NÃ£o Supervisionado)** | Treina o K-Means (`k=8`) com dados **normalizados** de **Petrolina**. |
| **GeraÃ§Ã£o de Labels** | O modelo treinado Ã© aplicado para classificar as semanas de **Garanhuns**, criando a *feature* `cluster`.
| **Treino de RegressÃ£o** | Treina um **RandomForestRegressor** para prever a **`umidade`** semanal de Garanhuns.
| **Treino de ClassificaÃ§Ã£o** | Treina um **DecisionTreeClassifier** para prever o **`cluster`** semanal de Garanhuns (validaÃ§Ã£o da consistÃªncia dos grupos).
| **Registro MLOps** | MÃ©tricas dos modelos supervisionados sÃ£o logadas no **MLFlow** e os modelos (`.pkl`) e relatÃ³rios de classificaÃ§Ã£o sÃ£o enviados ao **MinIO** (Data Lake).

**VariÃ¡veis e MÃ©tricas:** 

| VariÃ¡vel | AgregaÃ§Ã£o Semanal | Utilizado no K-Means (Treino) |
| :--- | :--- | :--- |
| `temp_ar` | MÃ©dia | Sim |
| `umidade` | MÃ©dia | Sim |
| `radiacao` | MÃ©dia | Sim |
| `pressao` | MÃ©dia | Sim |
| `vento_vel` | MÃ©dia | Sim |
| `precipitacao` | Soma (`sum`) | Sim |

| Modelo | VariÃ¡vel Alvo | MÃ©tricas Chave |
| :--- | :--- | :--- |
| **RandomForestRegressor** | `umidade` | MAE, RÂ² |
| **DecisionTreeClassifier** | `cluster` | AcurÃ¡cia, Classification Report|

**Quando usar:** ApÃ³s o processamento dos dados, para identificar padrÃµes climÃ¡ticos.

## 10. Scripts

### ğŸ”§ `scripts/send_inmet_to_tb.py`

Script para enviar dados limpos processados para o ThingsBoard. Este Ã© o primeiro passo do pipeline de dados.

**Uso:**

```bash
# Linux / macOS
python scripts/send_inmet_to_tb.py

# Windows
python scripts\send_inmet_to_tb.py
```

**Funcionalidades:**
- LÃª CSVs tratados de `data/processed/`
- Envia telemetria linha por linha para o ThingsBoard
- Suporta mÃºltiplos dispositivos (Petrolina, Garanhuns)
- Inclui delay para nÃ£o sobrecarregar o ThingsBoard

**ConfiguraÃ§Ã£o necessÃ¡ria:**
- Editar tokens dos dispositivos no dicionÃ¡rio `DEVICES`

**Fluxo:**
1. Este script envia dados limpos para o ThingsBoard
2. O ThingsBoard aplica uma Regra de NegÃ³cio para persistir dados brutos no MinIO
3. Execute `etl_minio_to_postgres.py` para transferir dados do MinIO para PostgreSQL

### ğŸ”§ `scripts/etl_minio_to_postgres.py`

Script de ETL para transferir dados do Data Lake (MinIO) para o Data Warehouse (PostgreSQL). Este script deve ser executado apÃ³s o ThingsBoard persistir os dados no MinIO atravÃ©s de sua Regra de NegÃ³cio.

**Uso:**

```bash
# Linux / macOS
python scripts/etl_minio_to_postgres.py

# Windows
python scripts\etl_minio_to_postgres.py
```

**Funcionalidades:**
- Conecta ao MinIO e lista arquivos CSV
- Carrega dados do MinIO (dados brutos persistidos pelo ThingsBoard)
- Cria tabela `inmet_raw` no PostgreSQL (se nÃ£o existir)
- Insere dados na tabela `inmet_raw` do PostgreSQL
- Organiza dados por dispositivo (Petrolina/Garanhuns)

**Fluxo:**
1. Execute `send_inmet_to_tb.py` para enviar dados ao ThingsBoard
2. O ThingsBoard persiste dados brutos no MinIO via Regra de NegÃ³cio
3. Execute este script para transferir dados do MinIO para PostgreSQL
4. O Jupyter Notebook extrai dados do PostgreSQL para modelagem

### ğŸ”§ `scripts/test_pipeline.py`

Script de testes para validar o pipeline completo.

**Uso:**

```bash
# Linux / macOS
python scripts/test_pipeline.py

# Windows
python scripts\test_pipeline.py
```

## 11. Troubleshooting

### âŒ Problema: ServiÃ§os nÃ£o iniciam

**SoluÃ§Ã£o:**

Comandos para Linux / macOS / Windows (PowerShell / CMD):

```bash
# Verificar logs
docker-compose logs

# Reiniciar serviÃ§os
docker-compose restart

# Reconstruir imagens
docker-compose up -d --build --force-recreate
```

### âŒ Problema: Porta jÃ¡ em uso

**SoluÃ§Ã£o:**
- Verifique se outra aplicaÃ§Ã£o estÃ¡ usando a porta
- Altere a porta no `docker-compose.yml` se necessÃ¡rio
- Use `docker-compose down` antes de subir novamente

#### Linux / macOS

```bash
# Verificar processos usando a porta
sudo lsof -i :8888  # Para porta 8888
sudo netstat -tulpn | grep :8888

# Parar serviÃ§os
docker-compose down
```

#### Windows (PowerShell)

```powershell
# Verificar processos usando a porta
netstat -ano | findstr :8888

# Parar serviÃ§os
docker-compose down
```

### âŒ Problema: Erro ao processar dados

**SoluÃ§Ã£o:**
- Verifique se os arquivos CSV estÃ£o em `/data/raw/` com a estrutura correta
- Confirme que o encoding Ã© `latin1`
- Verifique os logs do Jupyter: `docker-compose logs jupyterlab`

Comandos para Linux / macOS / Windows:

```bash
docker-compose logs jupyterlab
```

### âŒ Problema: PostgreSQL nÃ£o conecta

**SoluÃ§Ã£o:**
- Verifique se o serviÃ§o estÃ¡ rodando: `docker-compose ps postgres`
- Confirme credenciais: `postgres` / `postgres`
- Acesse via Adminer: `http://localhost:8085`
- Verifique a conexÃ£o no notebook: `postgresql://postgres:postgres@postgres:5432/clima`

### âŒ Problema: MLFlow nÃ£o salva modelos

**SoluÃ§Ã£o:**
- Verifique se o volume `./mlflow` estÃ¡ montado corretamente
- Confirme permissÃµes de escrita no diretÃ³rio
- Verifique logs: `docker-compose logs mlflow`

```bash
# Verificar permissÃµes (Linux / macOS)
ls -la mlflow/

# Ver logs (Linux / macOS / Windows)
docker-compose logs mlflow
```

### âŒ Problema: PostgreSQL nÃ£o conecta

**SoluÃ§Ã£o:**
- Verifique se o serviÃ§o estÃ¡ rodando: `docker-compose ps postgres`
- Confirme credenciais: `postgres` / `postgres`
- Acesse via Adminer: `http://localhost:8085`

### ğŸ› ï¸ Comandos Ãšteis

Comandos para Linux / macOS / Windows (PowerShell / CMD):

```bash
# Parar todos os serviÃ§os
docker-compose down

# Parar e remover volumes
docker-compose down -v

# Ver logs de um serviÃ§o especÃ­fico
docker-compose logs -f jupyterlab

# Executar comando em um container
docker-compose exec jupyterlab bash

# Limpar recursos nÃ£o utilizados
docker system prune -a

# Ver uso de recursos
docker stats
```

## 12. Resultados e ConclusÃµes

### ğŸ“Š Dados Processados

- **Total de registros:** ~87.000 registros horÃ¡rios (por ano)
- **PerÃ­odo:** 2020-2024
- **EstaÃ§Ãµes:** 2 (Petrolina e Garanhuns)
- **VariÃ¡veis climÃ¡ticas:** 6 principais

### ğŸ¤– Modelo K-Means

- **MÃ©todo:** Clustering nÃ£o-supervisionado
- **Features:** AgregaÃ§Ãµes semanais de variÃ¡veis climÃ¡ticas
- **AvaliaÃ§Ã£o:** Silhouette score
- **Versionamento:** MLFlow

### ğŸ“ˆ VisualizaÃ§Ã£o

- **Plataforma:** ThingsBoard
- **Dashboards:** PadrÃµes climÃ¡ticos por cluster
- **Interatividade:** Filtros por perÃ­odo, estaÃ§Ã£o e variÃ¡vel

### ğŸ“„ RelatÃ³rio TÃ©cnico

O relatÃ³rio final em PDF, contendo a arquitetura, metodologia, resultados e conclusÃµes, serÃ¡ enviado na atividade da entrega.

## ğŸ“š ReferÃªncias

- [INMET - Instituto Nacional de Meteorologia](https://portal.inmet.gov.br/)
- [ThingsBoard - DocumentaÃ§Ã£o](https://thingsboard.io/docs/)
- [MLFlow - DocumentaÃ§Ã£o](https://www.mlflow.org/docs/latest/index.html)
- [Scikit-learn K-Means](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [FastAPI - DocumentaÃ§Ã£o](https://fastapi.tiangolo.com/)
- [Docker - DocumentaÃ§Ã£o](https://docs.docker.com/)
- [PostgreSQL - DocumentaÃ§Ã£o](https://www.postgresql.org/docs/)
- [MinIO - DocumentaÃ§Ã£o](https://min.io/docs/)

## ğŸ“ LicenÃ§a

Este projeto Ã© desenvolvido para fins acadÃªmicos no contexto da disciplina de AnÃ¡lise e VisualizaÃ§Ã£o de Dados da CESAR School.

## ğŸ¤ Equipe

Este Ã© um projeto acadÃªmico desenvolvido pela equipe **Cobalto** ([ver membros](#2-membros-do-projeto)).

---

<div align="center">

**Desenvolvido com â¤ï¸ pela equipe Cobalto**

[â¬† Voltar ao topo](#-avd---pipeline-de-bi-climÃ¡tico)

</div>
