# üçá AVD - Pipeline de BI Clim√°tico para Viticultura 

## 1. Introdu√ß√£o e Objetivo

Este projeto implementa um pipeline de Business Intelligence (BI) para an√°lise e visualiza√ß√£o de dados meteorol√≥gicos do INMET (Instituto Nacional de Meteorologia), focando no estado de Pernambuco, com √™nfase no **Vale do S√£o Francisco**.

O objetivo central √© aplicar t√©cnicas de **Agrupamento (Clustering) K-Means** para identificar **Padr√µes Clim√°ticos Chave** durante fases cr√≠ticas da videira, como a flora√ß√£o e a matura√ß√£o, utilizando dados agregados de temperatura, umidade e radia√ß√£o solar. O resultado deste agrupamento deve ser visualizado em dashboards interativos (ThingsBoard/Trendz).

## 2. Membros do Projeto

| Nome | Usu√°rio |
| :--- | :--- |
| Lisa Matubara | `lm` |
| Luziane Santos | `lps` |
| Maria J√∫lia Peixoto | `mjpo` |
| Matheus Velame | `mvp2` |
| Paulo Rago | `prcr` |
| Tha√≠s Aguiar | `thcba` |

* **Disciplina:** An√°lise e Visualiza√ß√£o de Dados - 2025.2
* **Institui√ß√£o:** CESAR School

## 3. Arquitetura do Pipeline

A solu√ß√£o √© baseada em cont√™ineres Docker e orquestrada via Docker Compose, abrangendo as seguintes camadas:

| Servi√ßo | Fun√ß√£o Principal | Porta |
| :--- | :--- | :--- |
| **FastAPI** | Interface de ingest√£o dos dados brutos do INMET e integra√ß√£o com MinIO/S3. | `8060` |
| **MinIO/S3** | Armazenamento de dados brutos e modelos. | - |
| **Snowflake** | Estrutura√ß√£o de dados tratados (Simulado por `SQLite`/`PostgreSQL` em ambiente local). | - |
| **Jupyter Notebook** | Ambiente de limpeza, agrega√ß√£o de features e modelagem K-Means. | `8888` |
| **MLFlow** | Registro e versionamento do modelo de K-Means e artefatos. | `5000` |
| **Trendz Analytics** | Visualiza√ß√£o dos dados e dashboards interativos. | `8888` |

**Fluxo Geral:**

1. Os dados brutos do INMET s√£o ingeridos e salvos no S3/MinIO.
2. Os dados s√£o estruturados no Snowflake .
3. O Jupyter Notebook l√™ a base estruturada, aplica o K-Means e registra o modelo no MLFlow.
4. O dashboard no ThingsBoard/Trendz consome os resultados do agrupamento para gerar visualiza√ß√µes de padr√µes clim√°ticos.

## 4. Estrutura do Reposit√≥rio

| Caminho | Descri√ß√£o |
| :--- | :--- |
| `docker-compose.yml` | Orquestra√ß√£o dos cont√™ineres da infraestrutura. |
| `fastapi/` | Camada de ingest√£o de dados (API). |
| `jupyterlab/` | Dockerfile e configs do ambiente Jupyter. |
| `mlflow/` | Configura√ß√£o e armazenamento de experimentos. |
| `notebooks/` | Notebooks de tratamento, modelagem e visualiza√ß√£o. |
| `sql_scripts/` | Scripts SQL de estrutura√ß√£o e consultas (DML/DDL). |
| `reports/` | **Local de entrega do Relat√≥rio T√©cnico em PDF**. |
| `trendz/` | Dashboards e configura√ß√µes exportadas. |

## 5. Instru√ß√µes de Execu√ß√£o

Siga os passos abaixo para levantar a infraestrutura, executar o pipeline e visualizar o dashboard:

### 5.1. Pr√©-requisitos

* Docker e Docker Compose instalados.
* Conex√£o est√°vel com a internet.

### 5.2. Configurar Vari√°veis de Ambiente

1.  Crie o arquivo `.env` na pasta `fastapi/` com as credenciais do ThingsBoard:
    ```bash
    cd fastapi
    cp .env.example .env
    ```
    
    Edite o arquivo `.env` e configure:
    ```env
    THINGSBOARD_URL=http://thingsboard:9090
    THINGSBOARD_TENANT_USER=tenant@thingsboard.org
    THINGSBOARD_TENANT_PASSWORD=tenant
    THINGSBOARD_DEVICE_ID_PETROLINA=<SEU_DEVICE_ID_PETROLINA>
    THINGSBOARD_DEVICE_ID_GARANHUNS=<SEU_DEVICE_ID_GARANHUNS>
    ```
    
    > **Nota:** Voc√™ precisar√° obter os Device IDs ap√≥s criar os dispositivos no ThingsBoard (veja se√ß√£o 5.2.1).

2.  Volte para a raiz do projeto:
    ```bash
    cd ..
    ```

### 5.2.1. Configurar ThingsBoard

1.  Acesse o ThingsBoard em `http://localhost:8090` (aguarde o servi√ßo inicializar completamente).
2.  Fa√ßa login com as credenciais padr√£o:
    - Usu√°rio: `tenant@thingsboard.org`
    - Senha: `tenant`
3.  Crie dois dispositivos:
    - **INMET_Petrolina**
    - **INMET_Garanhuns**
4.  Para cada dispositivo:
    - V√° em **Details** ‚Üí copie o **Device ID** e cole no arquivo `.env` do FastAPI.
    - Copie o **Access Token** do dispositivo (ser√° usado pelo script loader).

### 5.3. Subir a Infraestrutura

1.  Na raiz do projeto, construa as imagens e suba todos os servi√ßos:
    ```bash
    docker-compose up -d --build
    ```
    
    Este comando sobe os seguintes servi√ßos:
    - **fastapi** ‚Äì API em `http://localhost:8000`
    - **jupyterlab** ‚Äì ambiente de notebooks em `http://localhost:8888`
    - **thingsboard** ‚Äì plataforma IoT em `http://localhost:8090`
    - **thingsboard-postgres** ‚Äì banco usado pelo ThingsBoard
    - **minio** ‚Äì armazenamento S3-compat√≠vel em `http://localhost:9001`
    - **mlflow** ‚Äì registro de modelos em `http://localhost:5000`
    - **tb-loader** ‚Äì carrega CSVs tratados e envia para o ThingsBoard
    - **inmet-ingest** ‚Äì chama a API FastAPI para ler dados do ThingsBoard e salvar no MinIO

### 5.4. Execu√ß√£o do Pipeline

1.  Acesse o Jupyter Notebook (porta `8888`): `http://localhost:8888`
2.  Execute o notebook **`01_tratamento_dados_inmet.ipynb`** para:
    * Carregar dados brutos (do `/data/raw`).
    * Limpar nulos (interpola√ß√£o) e salvar dados tratados (no `/data/processed`).
3.  **Carregamento Autom√°tico para ThingsBoard:**
    * O servi√ßo `tb-loader` no Docker Compose automaticamente detecta os CSVs tratados e envia para o ThingsBoard.
    * Voc√™ pode verificar os logs: `docker-compose logs tb-loader`
    * Ou executar manualmente: `docker-compose run --rm tb-loader python send_inmet_to_tb.py`
4.  **Ingest√£o de Dados do ThingsBoard para MinIO:**
    * Ap√≥s o `tb-loader` finalizar, o servi√ßo `inmet-ingest` automaticamente chama a API FastAPI.
    * A API busca a telemetria do ThingsBoard e salva como CSV no MinIO.
    * Endpoint manual: `POST http://localhost:8000/ingest/inmet`
5.  **[ETAPA MANUAL: Carregamento para o Banco de Dados]**
    * Execute os scripts SQL em `sql_scripts/` para criar o schema no Snowflake (ou Postgres/SQLite).
    * Use o FastAPI ou um script auxiliar no Jupyter para carregar os dados tratados (CSV em `/data/processed`) para a tabela do Snowflake.
6.  Execute o notebook **`02_modelagem_kmeans.ipynb`** para:
    * Ler os dados estruturados do Snowflake.
    * Tratar Outliers e Aggregar features (Semanal).
    * Treinar e registrar o modelo K-Means no MLFlow (`http://localhost:5000`).

### 5.5. Endpoints da API FastAPI

Principais endpoints dispon√≠veis:

- `GET /` ‚Äì Informa√ß√µes da API e lista de endpoints
- `GET /health` ‚Äì Health check
- `POST /ingest/inmet` ‚Äì Busca telemetria do ThingsBoard e salva no MinIO
- `POST /webhook/inmet/{device_name}` ‚Äì Recebe telemetria do ThingsBoard via webhook
- `GET /minio/files` ‚Äì Lista arquivos no MinIO
- `GET /minio/stats` ‚Äì Estat√≠sticas dos dados no MinIO
- `GET /api/dados-processados` ‚Äì Lista dados processados dispon√≠veis
- `GET /api/dados-processados/{cidade}/{ano}` ‚Äì Obt√©m dados tratados espec√≠ficos
- `GET /api/dados-agregados/clusters` ‚Äì Obt√©m dados agregados com clusters
- `POST /api/modelo/predict` ‚Äì Faz predi√ß√£o de cluster para novos dados

### 5.6. Visualiza√ß√£o do Dashboard

1.  Acesse o ThingsBoard em `http://localhost:8090`
2.  Navegue at√© os dispositivos **INMET_Petrolina** e **INMET_Garanhuns** para visualizar a telemetria em tempo real.
3.  Importe o dashboard de agrupamento (arquivos em `trendz/`) se dispon√≠vel.
4.  O dashboard deve exibir:
    * A distribui√ß√£o das semanas nos clusters identificados.
    * Gr√°ficos de dispers√£o coloridos por cluster para vari√°veis-chave (e.g., Temperatura vs. Umidade).
    * Pain√©is com as m√©dias de cada grupo clim√°tico.

## 6. Resultados e Conclus√µes

* **Relat√≥rio T√©cnico:** O relat√≥rio final em PDF, contendo a arquitetura, metodologia, resultados e conclus√µes, ser√° salvo no diret√≥rio `/reports/` antes da entrega.